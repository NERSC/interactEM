x-backend-base:
  &backend-base
    image: '${DOCKER_IMAGE_BACKEND?Variable not set}:${TAG-latest}'
    build:
      context: backend/
      args:
        INSTALL_DEV: ${INSTALL_DEV-false}
      dockerfile: ../docker/Dockerfile.fastapi
      additional_contexts:
        interactem-base: service:base
    env_file:
      - .env
    environment:
      - APP_DOMAIN=${APP_DOMAIN}
      - APP_ENVIRONMENT=${APP_ENVIRONMENT}
      - APP_BACKEND_CORS_ORIGINS=${APP_BACKEND_CORS_ORIGINS}
      - APP_SECRET_KEY=${APP_SECRET_KEY?Variable not set}
      - APP_FIRST_SUPERUSER_USERNAME=${APP_FIRST_SUPERUSER_USERNAME?Variable not set}
      - APP_FIRST_SUPERUSER_PASSWORD=${APP_FIRST_SUPERUSER_PASSWORD?Variable not set}
      - APP_POSTGRES_SERVER=db
      - APP_POSTGRES_PORT=${APP_POSTGRES_PORT}
      - APP_POSTGRES_DB=${APP_POSTGRES_DB}
      - APP_POSTGRES_USER=${APP_POSTGRES_USER?Variable not set}
      - APP_POSTGRES_PASSWORD=${APP_POSTGRES_PASSWORD?Variable not set}
      - APP_SENTRY_DSN=${APP_SENTRY_DSN}
      - APP_NATS_CREDS_FILE=/backend.creds
      - APP_NATS_FRONTEND_CREDS=/frontend.creds
      - APP_GITHUB_USERNAME=${APP_GITHUB_USERNAME}
      - APP_GITHUB_TOKEN=${APP_GITHUB_TOKEN}
      - APP_ORCHESTRATOR_API_KEY=${APP_ORCHESTRATOR_API_KEY?Variable not set}
      - NATS_CREDS_FILE=/backend.creds
      - NATS_SECURITY_MODE=creds
      - NATS_STREAM_STORAGE_TYPE=file
    volumes:
      - "./conf/nats-conf/out_jwt/backend.creds:/backend.creds"
      - "./conf/nats-conf/out_jwt/frontend.creds:/frontend.creds"

services:
  base:
    build:
      context: backend/
      dockerfile: ../docker/Dockerfile.base

  nats-config-generator:
    image: natsio/nats-box:latest
    user: "${USER_ID:-1000}:${GROUP_ID:-1000}"
    volumes:
      - "./conf/nats-conf:/nats-conf"
    working_dir: /nats-conf
    entrypoint: ""
    command: sh generate-auth-jwt.sh

  nats1:
    image: nats:2.11-alpine
    ports:
      - "4222:4222"
      - "8222:8222" # Monitoring port.
      - "9222:9222" # websocket
    command: >
      -c /etc/nats/nats.conf
    volumes:
      - "./conf/nats-conf/nats1.conf:/etc/nats/nats.conf"
      - "./conf/nats-conf/out_jwt/auth.conf:/etc/nats/auth.conf"
      - "./conf/nats-conf/websocket.conf:/etc/nats/websocket.conf"
    depends_on:
      nats-config-generator:
        condition: service_completed_successfully

  nats2:
    image: nats:2.11-alpine
    command: >
      -c /etc/nats/nats.conf
    volumes:
      - "./conf/nats-conf/nats2.conf:/etc/nats/nats.conf"
      - "./conf/nats-conf/out_jwt/auth.conf:/etc/nats/auth.conf"
      - "./conf/nats-conf/websocket.conf:/etc/nats/websocket.conf"
    depends_on:
      nats-config-generator:
        condition: service_completed_successfully
      nats1:
        condition: service_started

  nats3:
    image: nats:2.11-alpine
    command: >
      -c /etc/nats/nats.conf
    volumes:
      - "./conf/nats-conf/nats3.conf:/etc/nats/nats.conf"
      - "./conf/nats-conf/out_jwt/auth.conf:/etc/nats/auth.conf"
      - "./conf/nats-conf/websocket.conf:/etc/nats/websocket.conf"
    depends_on:
      nats-config-generator:
        condition: service_completed_successfully
      nats2:
        condition: service_started

  # Checks for health of nats server before allowing others to start up
  nats-healthcheck:
    image: curlimages/curl
    command: > # better command than sleep infinity because it exits more quickly
      /bin/sh -c "trap 'exit' TERM; while true; do sleep 1; done"
    depends_on:
      nats1:
        condition: service_started
      nats2:
        condition: service_started
      nats3:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "--connect-timeout", "3", "http://nats1:8222/healthz?js-enabled-only=true"]
      start_period: "3s"
      interval: "14s"
      timeout: "3s"
      retries: "3"

    
  db:
    image: postgres:12
    restart: always
    volumes:
      - app-db-data:/var/lib/postgresql/data/pgdata
    env_file:
      - .env
    environment:
      - PGDATA=/var/lib/postgresql/data/pgdata
      - POSTGRES_PASSWORD=${APP_POSTGRES_PASSWORD?Variable not set}
      - POSTGRES_USER=${APP_POSTGRES_USER?Variable not set}
      - POSTGRES_DB=${APP_POSTGRES_DB?Variable not set}

  prestart:
    <<: *backend-base
    depends_on:
      db:
        condition: service_started
      nats-config-generator:
        condition: service_completed_successfully
    command: bash prestart.sh

  backend:
    <<: *backend-base
    restart: always
    depends_on:
      db:
        condition: service_started
      nats-healthcheck:
        condition: service_healthy
      prestart:
        condition: service_completed_successfully
    ports:
      - "8080:8000"

  frontend:
    image: '${DOCKER_IMAGE_FRONTEND?Variable not set}:${TAG-latest}'
    build:
      context: frontend/
      dockerfile: ../docker/Dockerfile.frontend
    depends_on:
      backend:
        condition: service_started
    ports:
      - "5173:80"
    volumes:
      - "./conf/nginx.conf:/etc/nginx/conf.d/default.conf"

  orchestrator:
    image: '${DOCKER_IMAGE_ORCHESTRATOR?Variable not set}:${TAG-latest}'
    restart: always
    depends_on:
      db:
        condition: service_started
      nats-healthcheck:
        condition: service_healthy
      backend:
        condition: service_started
    env_file:
      - .env
    environment:
      - NATS_CREDS_FILE=/backend.creds
      - NATS_SECURITY_MODE=creds
      - NATS_STREAM_STORAGE_TYPE=file
      - ORCHESTRATOR_API_KEY=${ORCHESTRATOR_API_KEY?Variable not set}
    volumes:
      - "./conf/nats-conf/out_jwt/backend.creds:/backend.creds"

    build:
      context: backend/
      additional_contexts:
        interactem-base: service:base
      dockerfile: ../docker/Dockerfile.orchestrator


  callout:
    image: '${DOCKER_IMAGE_CALLOUT?Variable not set}:${TAG-latest}'
    restart: always
    depends_on:
      db:
        condition: service_started
      nats-healthcheck:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - "./backend/callout/service/.env:/.env"
      - "./conf/nats-conf/out_jwt/:/nats-conf/"
    build: 
      context: backend/
      dockerfile: ../docker/Dockerfile.callout


  launcher:
    image: '${DOCKER_IMAGE_LAUNCHER?Variable not set}:${TAG-latest}'
    restart: always
    depends_on:
      nats-healthcheck:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - NATS_CREDS_FILE=/backend.creds
      - NATS_SECURITY_MODE=creds
      - LAUNCHER_SFAPI_KEY_PATH=/key.pem
      - LAUNCHER_NATS_SERVER_URL=nats://nats1:4222
      - NATS_STREAM_STORAGE_TYPE=file
    volumes:
      - "./conf/nats-conf/out_jwt/backend.creds:/backend.creds"
      - "${HOME}/.superfacility/key.pem:/key.pem"
    build: 
      context: backend/
      additional_contexts:
        interactem-base: service:base
      dockerfile: ../docker/Dockerfile.launcher

  metrics:
    image: '${DOCKER_IMAGE_METRICS?Variable not set}:${TAG-latest}'
    restart: always
    depends_on:
      db:
        condition: service_started
      nats-healthcheck:
        condition: service_healthy
      backend:
        condition: service_started
    env_file:
      - .env
    environment:
      - NATS_CREDS_FILE=/backend.creds
      - NATS_SECURITY_MODE=creds
      - NATS_STREAM_STORAGE_TYPE=file
    volumes:
      - "./conf/nats-conf/out_jwt/backend.creds:/backend.creds"

    build:
      context: backend/
      additional_contexts:
        interactem-base: service:base
      dockerfile: ../docker/Dockerfile.metrics

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./backend/metrics/monitoring-conf/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=240h'
      - '--web.enable-lifecycle'

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./backend/metrics/monitoring-conf/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./backend/metrics/monitoring-conf/grafana/dashboards:/var/lib/grafana/dashboards:ro

  vector:
    image: timberio/vector:0.50.0-alpine
    container_name: vector-aggregator
    ports:
      - "6000:6000"
      - "8686:8686"
    depends_on:
      nats-healthcheck:
        condition: service_healthy
    volumes:
      - vector_data:/vector-data-dir
      - "./conf/nats-conf/out_jwt/backend.creds:/backend.creds"
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        cat > /tmp/vector.yaml <<EOF
        data_dir: /vector-data-dir
        
        api:
          enabled: true
          address: 0.0.0.0:8686
          playground: false
        
        sources:
          vector:
            type: vector
            address: 0.0.0.0:6000
            version: "2"

        transforms:
          # Clean up all logs by removing unnecessary fields based on log type
          clean_logs:
            type: remap
            inputs:
              - vector
            source: |
              # Remove fields from agent logs
              if .log_type == "agent" {
                del(.file)
                del(.source_type)
              }
              # Remove fields from operator logs
              if .log_type == "operator" {
                del(.file)
                del(.source_type)
                del(.stream)
              }
              .

          # Route logs based on their type
          route_by_type:
            type: route
            inputs:
              - clean_logs
            route:
              vector_logs: '.log_type == "vector"'
              agent_logs: '.log_type == "agent"'
              operator_logs: '.log_type == "operator"'
        
        sinks:
          console:
            type: console
            inputs:
              - route_by_type.vector_logs
              - route_by_type.agent_logs
              - route_by_type.operator_logs
            target: stdout
            encoding:
              codec: json

          # NATS sink for vector logs
          nats_vector:
            type: nats
            inputs:
              - route_by_type.vector_logs
            url: nats://nats1:4222
            subject: "log.vector.{{ agent_id }}"
            encoding:
              codec: json
            auth:
              strategy: credentials_file
              credentials_file:
                path: /backend.creds

          # NATS sink for agent logs
          nats_agents:
            type: nats
            inputs:
              - route_by_type.agent_logs
            url: nats://nats1:4222
            subject: "log.agent.{{ agent_id }}"
            encoding:
              codec: json
            auth:
              strategy: credentials_file
              credentials_file:
                path: /backend.creds

          # NATS sink for operator logs
          nats_operators:
            type: nats
            inputs:
              - route_by_type.operator_logs
            url: nats://nats1:4222
            subject: "log.depl.{{ deployment_id }}.op.{{ operator_id }}"
            encoding:
              codec: json
            auth:
              strategy: credentials_file
              credentials_file:
                path: /backend.creds
        EOF
        vector --config /tmp/vector.yaml


volumes:
  app-db-data:
  prometheus_data:
  grafana_data:
  vector_data: